{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higgins - Time-Dependent Eulerian Current - Data Generator\n",
    "\n",
    "##### Includes: Seasonal averaging, global viscosity model, deep water linear dispersion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "import numpy as np\n",
    "import math\n",
    "import ftplib\n",
    "import xarray\n",
    "from tqdm.autonotebook import tqdm\n",
    "import glob\n",
    "import cmath\n",
    "import os\n",
    "import warnings\n",
    "from scipy import special\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import itertools\n",
    "import concurrent.futures\n",
    "from datetime import date, datetime, timedelta\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(path):\n",
    "    paths = glob.glob(path)\n",
    "    paths.sort(key=os.path.getmtime)\n",
    "    file = xarray.open_mfdataset(paths, combine='by_coords')\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader_Stokes(path):\n",
    "    file = xarray.open_mfdataset(path, combine='by_coords')\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dates_maker(start,end):\n",
    "    dates = []\n",
    "    current = start\n",
    "    dates.append(current.strftime('%Y%m%d'))\n",
    "    while current < end:\n",
    "        current += timedelta(days=1)\n",
    "        dates.append(current.strftime('%Y%m%d'))\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def higgins_convolution_parallel_variable_f_variable_k_equator1(lat):\n",
    "    \n",
    "    kernel_length = 300\n",
    "\n",
    "    global lons\n",
    "    \n",
    "    Ue_point = np.zeros([len(Us_u_array[:,0,0]),1,720]) + 0j\n",
    "    print(lat)\n",
    "            \n",
    "    kernel = np.zeros([300,1]) + 0j\n",
    "\n",
    "    w = 7.2921 * (10**-5) * 3600\n",
    "    latitude = np.linspace(-78,80,317)[lat]\n",
    "    \n",
    "    for lon in tqdm(range(lons)):\n",
    "        latitude_rad = latitude * np.pi/180\n",
    "        f = 2*w*np.sin(latitude_rad)\n",
    "        v = Az_array[lat,lon] * 3600\n",
    "        k = k_array[lat,lon]\n",
    "\n",
    "        for n in range(kernel_length):\n",
    "            if n > 0:\n",
    "                t = 3*n\n",
    "                K = (((2*k*(v**0.5))/((t*np.pi)**0.5)))*np.exp(-1j*f*t) - ((1j*f*np.exp(-1j*f*t)) *special.erfcx((4*k*k*v*t)**0.5))\n",
    "                kernel[n-1] = K\n",
    "    \n",
    "        U_forcing_list = Us_u_array[:,lat,lon] + (1j * Us_v_array[:,lat,lon])\n",
    "    \n",
    "        if math.isnan(U_forcing_list[0]) == 0:\n",
    "            U_forcing = np.reshape(U_forcing_list, (1,len(U_forcing_list)))\n",
    "    \n",
    "            for i in range(len(U_forcing_list)-1):\n",
    "                j = i+1\n",
    "                if j <= kernel_length:\n",
    "                    Us = U_forcing[0][:j]\n",
    "                    K = kernel[:j]\n",
    "                    Us_reverse = np.flip(Us)\n",
    "                    Us_vector = np.reshape(Us_reverse, (1,j))\n",
    "                else:\n",
    "                    Us = U_forcing[0][j-kernel_length:j]\n",
    "                    K = kernel[:kernel_length]\n",
    "                    Us_reverse = np.flip(Us)\n",
    "                    Us_vector = np.reshape(Us_reverse, (1,kernel_length))\n",
    "                matrix = np.dot(K,Us_vector)\n",
    "                Ue = sum(np.diag(matrix))\n",
    "                Ue_point[i+1,0,lon]=Ue*3\n",
    "                \n",
    "    del kernel\n",
    "        \n",
    "    return Ue_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2002,1,1)\n",
    "end = datetime(2014,12,31)\n",
    "delta = timedelta(days=1)\n",
    "dates = []\n",
    "current = start\n",
    "dates.append(current.strftime('%Y%m%d'))\n",
    "while current < end:\n",
    "    current += delta\n",
    "    dates.append(current.strftime('%Y%m%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.linspace(2002,2014,13)\n",
    "\n",
    "start = []\n",
    "end = []\n",
    "\n",
    "start.append(datetime(2002,1,1).strftime('%Y%m%d'))\n",
    "end.append(datetime(2002,2,28).strftime('%Y%m%d'))\n",
    "\n",
    "for year in years:\n",
    "    year = int(year)\n",
    "    spring_start = datetime(year,3,1)\n",
    "    spring_end = datetime(year,5,31)\n",
    "    start.append(spring_start.strftime('%Y%m%d'))\n",
    "    end.append(spring_end.strftime('%Y%m%d'))\n",
    "    \n",
    "    summer_start = datetime(year,6,1)\n",
    "    summer_end = datetime(year,8,31)\n",
    "    start.append(summer_start.strftime('%Y%m%d'))\n",
    "    end.append(summer_end.strftime('%Y%m%d'))\n",
    "    \n",
    "    autumn_start = datetime(year,9,1)\n",
    "    autumn_end = datetime(year,11,30)\n",
    "    start.append(autumn_start.strftime('%Y%m%d'))\n",
    "    end.append(autumn_end.strftime('%Y%m%d'))\n",
    "    \n",
    "    winter_start = datetime(year,12,1)\n",
    "    winter_end = datetime(year+1,2,28)\n",
    "    start.append(winter_start.strftime('%Y%m%d'))\n",
    "    end.append(winter_end.strftime('%Y%m%d'))\n",
    "    \n",
    "end[end.index('20040228')] = '20040229'\n",
    "end[end.index('20080228')] = '20080229'\n",
    "end[end.index('20120228')] = '20120229'\n",
    "\n",
    "index_start = []\n",
    "for d in start:\n",
    "    index_start.append(dates.index(d)*8)\n",
    "index_start.append(37984)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for master in range(len(index_start)-1):\n",
    "    master = master + 52 \n",
    "    j = index_start[master+1]\n",
    "    i = index_start[master] - 300\n",
    "    m = index_start[master]\n",
    "    \n",
    "    if i < 0:\n",
    "        i = 0\n",
    "        \n",
    "    stamp = j\n",
    "    print(stamp)\n",
    "    \n",
    "    location_stokes = '/Volumes/4YP/Data/Stokes_3hr/Stokes'\n",
    "    file_type = '.nc'\n",
    "    paths_stokes = []\n",
    "    for n in range(i,j):\n",
    "        s = str(n).zfill(6)\n",
    "        paths_stokes.append(location_stokes + s + file_type)\n",
    "    Us_file = loader_Stokes(paths_stokes)\n",
    "    Us_u_array = Us_file.uuss.values\n",
    "    Us_v_array = Us_file.vuss.values\n",
    "    time = Us_file.uuss['time'].values\n",
    "    \n",
    "    location_PFreq = '/Volumes/4YP/Data/PFreq_3hr/PFreq'\n",
    "    file_type = '.nc'\n",
    "    paths_PFreq = []\n",
    "    for n in range(m,j):\n",
    "        s = str(n).zfill(6)\n",
    "        paths_PFreq.append(location_PFreq + s + file_type)\n",
    "    PF_file = loader_Stokes(paths_PFreq)\n",
    "    k_file = ((2*np.pi*PF_file.fp)**2)/9.81\n",
    "    k_array = k_file.mean('time').values\n",
    "    \n",
    "    location_viscosity = '/Volumes/JCHD/Microplastics_Paper/Data/Az_24hr/Az'\n",
    "    file_type = '.nc'\n",
    "    paths_viscosity = []\n",
    "    ds = dates[int(m/8):int(j/8)]\n",
    "    if master > 38:\n",
    "        new_master = master - 4\n",
    "        j = index_start[new_master+1]\n",
    "        i = index_start[new_master] - 300\n",
    "        m = index_start[new_master]\n",
    "    if master > 42:\n",
    "        new_master = master - 8\n",
    "        j = index_start[new_master+1]\n",
    "        i = index_start[new_master] - 300\n",
    "        m = index_start[new_master]\n",
    "    if master > 46:\n",
    "        new_master = master - 12\n",
    "        j = index_start[new_master+1]\n",
    "        i = index_start[new_master] - 300\n",
    "        m = index_start[new_master]\n",
    "    if master > 50:\n",
    "        new_master = master - 16\n",
    "        j = index_start[new_master+1]\n",
    "        i = index_start[new_master] - 300\n",
    "        m = index_start[new_master]\n",
    "    ds = dates[int(m/8):int(j/8)]\n",
    "    for i in range(len(ds)):\n",
    "        paths_viscosity.append(location_viscosity + ds[i] + file_type)\n",
    "    Az_file = loader_Stokes(paths_viscosity)\n",
    "    Az_array = Az_file.Az.mean('time').values\n",
    "    \n",
    "    lat = list(range(len(Us_file.latitude)))\n",
    "    lons = len(Us_file.longitude)\n",
    "\n",
    "    cpus = mp.cpu_count()\n",
    "    p=mp.Pool(cpus)\n",
    "    output = p.map(higgins_convolution_parallel_variable_f_variable_k_equator1, tqdm(lat))\n",
    "    data = np.concatenate(output, axis=1)\n",
    "\n",
    "    dims = ('time', 'latitude', 'longitude')\n",
    "\n",
    "    U_ek = xarray.Dataset(\n",
    "        data_vars={\n",
    "                'U': (dims, data.real),\n",
    "                'V': (dims, data.imag)},\n",
    "        coords={\n",
    "                'time': Us_file.time,\n",
    "                'latitude': Us_file.latitude,\n",
    "                'longitude': Us_file.longitude}\n",
    "    )\n",
    "    \n",
    "    save_location = '/Volumes/JCHD/Microplastics_Paper/Data/Eulerian_3hr/Eulerian'\n",
    "    save_file_type_npy = '.npy'\n",
    "    save_file_type_nc = '.nc'\n",
    "        \n",
    "    save_path_npy = save_location + str(stamp).zfill(6) + save_file_type_npy\n",
    "    save_path_nc = save_location + str(stamp).zfill(6) + save_file_type_nc\n",
    "    \n",
    "    np.save(save_path_npy, data)\n",
    "    U_ek.to_netcdf(save_path_nc)\n",
    "    \n",
    "    del data\n",
    "    del output\n",
    "    del U_ek\n",
    "    del Us_u_array\n",
    "    del Us_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
